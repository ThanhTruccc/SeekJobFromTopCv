{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import Libraries and enviornment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLMs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from '.env' file\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY') # For LLM -- llama-3.1-8b (small) & mixtral-8x7b-32768 (large)\n",
    "os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY') # For embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\hello\\AppData\\Local\\Temp\\ipykernel_4664\\2694590058.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "### Build Index\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Set embeddings\n",
    "# embedding_model = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"dangvantuan/vietnamese-document-embedding\"\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\", \"trust_remote_code\": True},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_file_path = fr\"C:\\htN\\UIT\\learnin\\RAG_Techniques\\data\\alqac_2024\\training\\EDA\\law_articles.csv\"\n",
    "\n",
    "# Load CSV file\n",
    "loader = CSVLoader(file_path=csv_file_path)\n",
    "raw_docs = loader.load()\n",
    "\n",
    "for doc in raw_docs:\n",
    "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
    "\n",
    "# print(raw_docs)\n",
    "\n",
    "# Tạo lại documents với metadata mong muốn\n",
    "docs_list = []\n",
    "for doc in raw_docs:\n",
    "    # Parse nội dung từ page_content\n",
    "    content = doc.page_content\n",
    "    \n",
    "    # Tách các phần thông tin\n",
    "    parts = content.split(' content: ')\n",
    "    header = parts[0].split(' article_id: ')\n",
    "    id_law = header[0].replace('id_law: ', '')\n",
    "    article_id = header[1]\n",
    "    content = parts[1] if len(parts) > 1 else ''\n",
    "    \n",
    "    # Tạo document mới với metadata đã parse\n",
    "    new_doc = Document(\n",
    "        page_content=content.replace('\\n', ' '),  # Thay thế \\n bằng khoảng trắng trong content\n",
    "        metadata={\n",
    "            'title': f\"Điều {article_id} - {id_law}\",\n",
    "            'source': id_law,\n",
    "            'article_id': article_id\n",
    "        }\n",
    "    )\n",
    "    docs_list.append(new_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text splits generated: 4615\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "print(f\"Number of text splits generated: {len(doc_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add to vectorstore\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag\",\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "                search_type=\"similarity\",\n",
    "                search_kwargs={'k': 4}, # number of documents to retrieve\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Người nghiện ma túy từ đủ 18 tuổi trở lên bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc theo quy định của Luật Xử lý vi phạm hành chính khi bị phát hiện sử dụng chất ma túy một cách trái phép trong thời gian cai nghiện ma túy tự nguyện, đúng hay sai?\"\n",
    "question_type = \"Đúng/Sai\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what our doc looklike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Điều 32 - Luật Phòng, chống ma túy\n",
      "\n",
      "Source: Luật Phòng, chống ma túy\n",
      "\n",
      "Content: Đối tượng bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc  Người nghiện ma túy từ đủ 18 tuổi trở lên bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc theo quy định của Luật Xử lý vi phạm hành chính khi thuộc một trong các trường hợp sau đây:  1. Không đăng ký, không thực hiện hoặc tự ý chấm dứt cai nghiện ma túy tự nguyện;  2. Trong thời gian cai nghiện ma túy tự nguyện bị phát hiện sử dụng trái phép chất ma túy;  3. Người nghiện ma túy các chất dạng thuốc phiện không đăng ký, không thực hiện hoặc tự ý chấm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Title: {docs[0].metadata['title']}\\n\\nSource: {docs[0].metadata['source']}\\n\\nContent: {docs[0].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check document relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "# LLM\n",
    "llm = ChatGroq(model=\"deepseek-r1-distill-llama-70b\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out the non-relevant docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đối tượng bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc  Người nghiện ma túy từ đủ 18 tuổi trở lên bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc theo quy định của Luật Xử lý vi phạm hành chính khi thuộc một trong các trường hợp sau đây:  1. Không đăng ký, không thực hiện hoặc tự ý chấm dứt cai nghiện ma túy tự nguyện;  2. Trong thời gian cai nghiện ma túy tự nguyện bị phát hiện sử dụng trái phép chất ma túy;  3. Người nghiện ma túy các chất dạng thuốc phiện không đăng ký, không thực hiện hoặc tự ý chấm \n",
      " --------------------------------------------------\n",
      "binary_score='yes' \n",
      "\n",
      "Cai nghiện ma túy cho người từ đủ 12 tuổi đến dưới 18 tuổi  1. Người nghiện ma túy từ đủ 12 tuổi đến dưới 18 tuổi bị đưa vào cơ sở cai nghiện bắt buộc khi thuộc một trong các trường hợp sau đây:  a) Không đăng ký, không thực hiện hoặc tự ý chấm dứt cai nghiện ma túy tự nguyện;  b) Trong thời gian cai nghiện ma túy tự nguyện bị phát hiện sử dụng trái phép chất ma túy;  c) Người nghiện ma túy các chất dạng thuốc phiện không đăng ký, không thực hiện hoặc tự ý chấm dứt điều trị nghiện các chất dạng thuốc phiện bằng thuốc thay thế hoặc bị chấm \n",
      " --------------------------------------------------\n",
      "binary_score='no' \n",
      "\n",
      "Miễn chấp hành thời gian còn lại trong quyết định đưa vào cơ sở cai nghiện bắt buộc đối với người từ đủ 14 tuổi đến dưới 18 tuổi đang cai nghiện ma túy bắt buộc  Người từ đủ 14 tuổi đến dưới 18 tuổi đang cai nghiện ma túy bắt buộc mà bị phát hiện thực hiện hành vi phạm tội trước hoặc trong thời gian chấp hành quyết định cai nghiện ma túy bắt buộc và bị Tòa án xử phạt tù nhưng không được hưởng án treo thì được miễn chấp hành thời gian còn lại trong quyết định đưa vào cơ sở cai nghiện bắt buộc. \n",
      " --------------------------------------------------\n",
      "binary_score='no' \n",
      "\n",
      "Thời hạn cai nghiện ma túy bắt buộc đối với người nghiện ma túy từ đủ 12 tuổi đến dưới 18 tuổi là từ đủ 06 tháng đến 12 tháng.  4. Việc đưa người nghiện ma túy từ đủ 12 tuổi đến dưới 18 tuổi vào cơ sở cai nghiện bắt buộc do Tòa án nhân dân cấp huyện quyết định và không phải là biện pháp xử lý hành chính.  5. Ủy ban Thường vụ Quốc hội quy định trình tự, thủ tục Tòa án nhân dân xem xét, quyết định việc đưa người nghiện ma túy từ đủ 12 tuổi đến dưới 18 tuổi vào cơ sở cai nghiện bắt buộc. \n",
      " --------------------------------------------------\n",
      "binary_score='no' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_to_use = []\n",
    "for doc in docs:\n",
    "    print(doc.page_content, '\\n', '-'*50)\n",
    "    res = retrieval_grader.invoke({\"question\": question, \"document\": doc.page_content})\n",
    "    print(res,'\\n')\n",
    "    if res.binary_score == 'yes':\n",
    "        docs_to_use.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'article_id': '32', 'source': 'Luật Phòng, chống ma túy', 'title': 'Điều 32 - Luật Phòng, chống ma túy'}, page_content='Đối tượng bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc  Người nghiện ma túy từ đủ 18 tuổi trở lên bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc theo quy định của Luật Xử lý vi phạm hành chính khi thuộc một trong các trường hợp sau đây:  1. Không đăng ký, không thực hiện hoặc tự ý chấm dứt cai nghiện ma túy tự nguyện;  2. Trong thời gian cai nghiện ma túy tự nguyện bị phát hiện sử dụng trái phép chất ma túy;  3. Người nghiện ma túy các chất dạng thuốc phiện không đăng ký, không thực hiện hoặc tự ý chấm')]\n"
     ]
    }
   ],
   "source": [
    "print(docs_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Được rồi, mình cần phân tích câu hỏi này. Câu hỏi là về việc người nghiện ma túy từ đủ 18 tuổi trở lên có bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc khi bị phát hiện sử dụng ma túy trái phép trong thời gian cai nghiện tự nguyện hay không.\n",
      "\n",
      "Mình xem qua tài liệu được cung cấp, đó là Điều 32 của Luật Phòng, chống ma túy. Điều này quy định rõ các trường hợp áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc. Cụ thể, Khoản 2 của Điều 32 nói rằng nếu trong thời gian cai nghiện tự nguyện mà bị phát hiện sử dụng trái phép chất ma túy, thì người đó sẽ bị áp dụng biện pháp này.\n",
      "\n",
      "Câu hỏi hoàn toàn khớp với trường hợp được nêu trong Khoản 2 của Điều 32. Do đó, câu trả lời là đúng.\n",
      "</think>\n",
      "\n",
      "Luật Phòng, chống ma túy,32,,Đúng\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a professional in answering legal law questions. Use the provided documents to answer those question. Always read the documents carefully before answer. Please answer the question based on the type of the question. You must always answer the question in Vietnamese. You are provided with the following:\n",
    "1. A question.\n",
    "2. The type of the question\n",
    "3. A set of documents that were referenced in generating the answer.\n",
    "\n",
    "If the question is marked \"Trắc nghiệm\", answering the only choice that you think are right based on the document you are provided.\n",
    "Example: \n",
    "With the question: \"Thông báo nghỉ hưu đối với viên chức được cơ quan, đơn vị, tổ chức ban hành trong thời gian bao lâu trước khi đến thời hạn viên chức nghỉ hưu? \",Luật Viên chức,46,\"'A': '06 tháng', 'B': '04 tháng', 'C': '03 tháng', 'D': '02 tháng'\", you will answer \"B: 04 tháng\"\n",
    "\n",
    "If the question is marked \"Đúng/Sai\", choose Đúng or Sai based on the knowledge you've been provided, provide the name of the law, the id of the law (This is usually behind the \"Điều\" part), and your answer, based on the example answer, not answer anything else.\n",
    "Example:\n",
    "For the question: \"Việc lựa chọn nơi cư trú của vợ chồng do phong tục tập quán của gia đình nhà chồng quyết định, đúng hay sai?\", you will answer: \"Luật Hôn nhân và gia đình,20,,Sai\"\n",
    "\n",
    "If the question is marked \"Tự luận\", answer based on the documents that you've been provided, provide the name of the law, the id of the law (This is usually behind the \"Điều\" part), and your answer, based on the example answer, not answer anything else.\n",
    "Example:\n",
    "With the question: \"Cơ quan nào có trách nhiệm thống nhất quản lý nhà nước về điện ảnh?\", you should answer: \"Luật Điện ảnh,45,,Chính phủ\"\n",
    "\n",
    "Question: {question} \n",
    "Type of question: {question_type}\n",
    "Context: {documents} \n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved documents: \\n\\n <docs>{documents}</docs> \\n\\n User question: <question>{question}</question> \\n\\n Question Type: <question_type>{question_type}</question_type>\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(f\"<doc{i+1}>:\\nTitle:{doc.metadata['title']}\\nSource:{doc.metadata['source']}\\nContent:{doc.page_content}\\n</doc{i+1}>\\n\" for i, doc in enumerate(docs))\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"documents\":format_docs(docs_to_use), \"question\": question, \"question_type\": question_type})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in 'generation' answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        ...,\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n <facts>{documents}</facts> \\n\\n LLM generation: <generation>{generation}</generation>\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "response = hallucination_grader.invoke({\"documents\": format_docs(docs_to_use), \"generation\": generation})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlight used docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Data model\n",
    "class HighlightDocuments(BaseModel):\n",
    "    \"\"\"Return the specific part of a document used for answering the question.\"\"\"\n",
    "\n",
    "    id: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of id of docs used to answers the question\"\n",
    "    )\n",
    "\n",
    "    title: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of titles used to answers the question\"\n",
    "    )\n",
    "\n",
    "    source: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of sources used to answers the question\"\n",
    "    )\n",
    "\n",
    "    segment: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of direct segements from used documents that answers the question\"\n",
    "    )\n",
    "\n",
    "\n",
    "# parser\n",
    "parser = PydanticOutputParser(pydantic_object=HighlightDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an advanced assistant for document search and retrieval. You are provided with the following:\n",
    "1. A question.\n",
    "2. A generated answer based on the question.\n",
    "3. A set of documents that were referenced in generating the answer.\n",
    "\n",
    "You are a professional in answering legal law questions. Use the provided documents to answer those question. Please answer the question based on the type of the question. You must always answer the question in Vietnamese. You are provided with the following:\n",
    "1. A question.\n",
    "2. A generated answer based on the question.\n",
    "3. A set of documents that were referenced in generating the answer.\n",
    "\n",
    "If the question is marked \"Trắc nghiệm\", answering the only choice that you think are right.\n",
    "Example: \n",
    "With the question: \"Thông báo nghỉ hưu đối với viên chức được cơ quan, đơn vị, tổ chức ban hành trong thời gian bao lâu trước khi đến thời hạn viên chức nghỉ hưu? \",Luật Viên chức,46,\"'A': '06 tháng', 'B': '04 tháng', 'C': '03 tháng', 'D': '02 tháng'\", you will answer \"B: 04 tháng\"\n",
    "\n",
    "If the question is marked \"Đúng/Sai\", choose Đúng or Sai based on the knowledge you've been provided, and provide the law that you based on.\n",
    "Example:\n",
    "For the question: \"Việc lựa chọn nơi cư trú của vợ chồng do phong tục tập quán của gia đình nhà chồng quyết định, đúng hay sai?\", you will answer: \"Luật Hôn nhân và gia đình,20,,Sai\"\n",
    "\n",
    "If the question is marked \"Tự luận\", answer based on the documents that you've been provided, provide the name of the law, the id of the law, and your answer.\n",
    "Example:\n",
    "With the question: \"Cơ quan nào có trách nhiệm thống nhất quản lý nhà nước về điện ảnh?\", you should answer: \"Luật Điện ảnh,45,,Chính phủ\"\n",
    "\n",
    "Question: {question} \n",
    "Type of question: {question_type}\n",
    "Context: {documents} \n",
    "Answer:\n",
    "\n",
    "Ensure that:\n",
    "- (Important) Each segment is an exact match to a part of the document and is fully contained within the document text.\n",
    "- The relevance of each segment to the generated answer is clear and directly supports the answer provided.\n",
    "- (Important) If you didn't used the specific document don't mention it.\n",
    "\n",
    "Used documents: <docs>{documents}</docs> \\n\\n User question: <question>{question}</question> \\n\\n Generated answer: <answer>{generation}</answer>\n",
    "\n",
    "<format_instruction>\n",
    "{format_instructions}\n",
    "</format_instruction>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template= system,\n",
    "    input_variables=[\"documents\", \"question\", \"generation\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Chain\n",
    "doc_lookup = prompt | llm | parser\n",
    "\n",
    "# Run\n",
    "lookup_response = doc_lookup.invoke({\"documents\":format_docs(docs_to_use), \"question\": question, \"question_type\": question_type, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: doc1\n",
      "Title: Điều 32 - Luật Phòng, chống ma túy\n",
      "Source: Luật Phòng, chống ma túy\n",
      "Text Segment: Người nghiện ma túy từ đủ 18 tuổi trở lên bị áp dụng biện pháp xử lý hành chính đưa vào cơ sở cai nghiện bắt buộc theo quy định của Luật Xử lý vi phạm hành chính khi thuộc một trong các trường hợp sau đây:  2. Trong thời gian cai nghiện ma túy tự nguyện bị phát hiện sử dụng trái phép chất ma túy;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, title, source, segment in zip(lookup_response.id, lookup_response.title, lookup_response.source, lookup_response.segment):\n",
    "    print(f\"ID: {id}\\nTitle: {title}\\nSource: {source}\\nText Segment: {segment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(fr\"C:\\htN\\UIT\\learnin\\RAG_Techniques\\data\\alqac_2024\\training\\EDA\\train_alqac.csv\")\n",
    "\n",
    "# df['new_Answer'] = (df['law_id'].fillna('') + ',' + \n",
    "#                    df['article_id'].astype(str).replace('nan', '') + ',' + \n",
    "#                    df['choices'].fillna('') + ',' + \n",
    "#                    df['Answer'].fillna(''))\n",
    "\n",
    "# df.to_csv(fr\"C:\\htN\\UIT\\learnin\\RAG_Techniques\\data\\alqac_2024\\training\\EDA\\train_alqac_compare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def process_questions(csv_file):\n",
    "    # Đọc file CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    results = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        question = row['Question']  # Giả sử cột chứa câu hỏi tên là 'question'\n",
    "        question_type = row['question_type']\n",
    "\n",
    "        start = time.time()\n",
    "        # 1. Retrieve docs\n",
    "        docs = retriever.invoke(question)\n",
    "        \n",
    "        # 2. Filter relevant docs\n",
    "        docs_to_use = []\n",
    "        for doc in docs:\n",
    "            res = retrieval_grader.invoke({\"question\": question, \"document\": doc.page_content, \"question_type\": question_type})\n",
    "            if res.binary_score == 'yes':\n",
    "                docs_to_use.append(doc)\n",
    "        \n",
    "        # 3. Generate answer\n",
    "        generation = rag_chain.invoke({\"documents\":format_docs(docs_to_use), \"question\": question, \"question_type\": question_type})\n",
    "        \n",
    "        # 4. Check hallucination\n",
    "        hallucination_check = hallucination_grader.invoke({\n",
    "            \"documents\": format_docs(docs_to_use), \n",
    "            \"generation\": generation\n",
    "        })\n",
    "        \n",
    "        # 5. Get used documents\n",
    "        used_docs = doc_lookup.invoke({\n",
    "            \"documents\":format_docs(docs_to_use), \n",
    "            \"question\": question, \n",
    "            \"generation\": generation\n",
    "        })\n",
    "        end = time.time()\n",
    "        answer = generation.split(\"</think>\")[-1].strip()\n",
    "        # 6. Store results\n",
    "        result = {\n",
    "            'question': question,\n",
    "            'question_type': question_type,\n",
    "            'answer': answer,\n",
    "            'not_hallucination': hallucination_check.binary_score,\n",
    "            'process_time': end - start,\n",
    "            'used_documents': used_docs,\n",
    "            # Thêm các thông tin khác nếu cần\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "    \n",
    "    # Convert to DataFrame và lưu kết quả\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('../results/results_reliable_rag.csv', index=False)\n",
    "\n",
    "csv_file = fr\"C:\\htN\\UIT\\learnin\\RAG_Techniques\\data\\alqac_2024\\training\\EDA\\train_alqac_compare.csv\"\n",
    "process_questions(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
